{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4a49d26-91bb-4861-a235-1dfea9a09a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% LOAD PACKAGES\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "from os import path\n",
    "from datetime import datetime, timedelta\n",
    "from scipy.optimize import least_squares\n",
    "import calendar\n",
    "from dateutil.relativedelta import relativedelta\n",
    "# import sklearn\n",
    "# from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8c31d43-1125-4668-a873-8b9a73dd07b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% SR CALCULATION\n",
    "# INPUT\n",
    "# sd_input: dataframe with daily catchment values for P, Ep, Q\n",
    "# Si_0: initial interception storage = 0\n",
    "# Si_max: maximum interception storage = 2.5mm\n",
    "# date_start, date_end: start and end 'month-day' of time-series (depending on hydro-year)\n",
    "# year_start, year_end: start and end year of time-series\n",
    "\n",
    "# OUTPUT\n",
    "# catchment: pandas dataframe with daily catchment values for P, Ep, Q, Pe, Et and Sd (based on initial Et estimate)\n",
    "\n",
    "# SD\n",
    "def sd_initial(sd_input, Si_0, Si_max, q_mean):\n",
    "\n",
    "    #read csv file for catchment of interest\n",
    "    # catchment = pd.read_csv(filename, sep=',', skiprows=0, index_col=0, skipinitialspace=True)\n",
    "    # catchment.index = pd.to_datetime(catchment.index)\n",
    "    sd_input = sd_input.loc[sd_input.date_start[0]:sd_input.date_end[0]]\n",
    "    \n",
    "    # soms is de start date eg 02-01 maar begint de timeseries pas 02-28: dan een jaar erbij optellen\n",
    "    if sd_input.index[0]>sd_input.date_start[0]:\n",
    "        sd_input.date_start = sd_input.date_start[0] + relativedelta(years=1)\n",
    "    \n",
    "    sd_input = sd_input.loc[sd_input.date_start[0]:sd_input.date_end[0]]\n",
    "    \n",
    "    # add columns for interception storage calculation\n",
    "    sd_input['Si_1'] = np.nan\n",
    "    sd_input['Pe'] = np.nan\n",
    "    sd_input['Si_2'] = np.nan\n",
    "    sd_input['Ei'] = np.nan\n",
    "    sd_input['Si_3'] = np.nan\n",
    "    sd_input['Et'] = np.nan\n",
    "    sd_input['Sd'] = np.nan\n",
    "    \n",
    "    # convert to numpy arrays\n",
    "    p = np.array(sd_input.p.values)\n",
    "    # q = np.array(sd_input.Q.values)\n",
    "    ep = np.array(sd_input.ep.values)\n",
    "    \n",
    "    si1 = np.zeros(len(sd_input))\n",
    "    pe = np.zeros(len(sd_input))\n",
    "    si2 = np.zeros(len(sd_input))\n",
    "    ei = np.zeros(len(sd_input))\n",
    "    si3 = np.zeros(len(sd_input))\n",
    "    et = np.zeros(len(sd_input))\n",
    "    sd = np.zeros(len(sd_input))\n",
    "    \n",
    "    #calculate interception storage and effective precipitation for all timesteps\n",
    "    for l in range(1,len(si1)):\n",
    "        si1[0] = p[0] + Si_0\n",
    "        pe[0] = max(0,si1[0]-Si_max)\n",
    "        si2[0] = si1[0] - pe[0]\n",
    "        ei[0] = min(si2[0],ep[0])\n",
    "        si3[0] = si2[0] - ei[0]\n",
    "    \n",
    "        si1[l] = p[l] + si3[l-1]\n",
    "        pe[l] = max(0,si1[l]-Si_max)\n",
    "        si2[l] = si1[l] - pe[l]\n",
    "        ei[l] = min(si2[l],ep[l])\n",
    "        si3[l] = si2[l] - ei[l]\n",
    "    \n",
    "    #water balance Et calculation (Et = Pe-Q)\n",
    "    Pe_mean = np.mean(pe)\n",
    "    EP_mean = np.mean(ep)\n",
    "    Q_mean = q_mean\n",
    "    Et_mean = Pe_mean - Q_mean\n",
    "    \n",
    "    #calculate daily Et (EP(daily)*(Et_sum/EP_sum)) and Sd\n",
    "    for l in range(1,np.size(sd_input.index)):\n",
    "        #if Pe < Q -> kan niet!\n",
    "        if Et_mean<0: \n",
    "            break            \n",
    "        et[0] = ep[0]/EP_mean * Et_mean\n",
    "        sd[0] = pe[0] - et[0]\n",
    "    \n",
    "        et[l] = ep[l]/EP_mean * Et_mean\n",
    "        sd[l] = min(0,sd[l-1]+pe[l]-et[l])\n",
    "        \n",
    "    sd_input.Si_1 = si1\n",
    "    sd_input.Si_2 = si2\n",
    "    sd_input.Si_3 = si3\n",
    "    sd_input.Pe = pe\n",
    "    sd_input.Ei = ei\n",
    "    sd_input.Sd = sd\n",
    "    sd_input.Et = et\n",
    "    \n",
    "    # if(sd_input.Sd.mean()==0):\n",
    "    #     sd_input.Sd=np.nan\n",
    "    \n",
    "    return sd_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42b7f394-d338-491a-ba77-2ed2ce1cae9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% function 2: Sr calculation based on return periods - INCLUDE MIN MAX APPROACH LIKE STIJN\n",
    "\n",
    "# INPUT\n",
    "# T: array of return periods of interest T=[2,5,10,15,20,30,40]\n",
    "# Sd: dataframe of Sd calculated in sd_iterations function\n",
    "# date_start, date_end: start and end 'month-day' of time-series (depending on hydro-year)\n",
    "# year_start, year_end: start and end year of time-series\n",
    "# it: amount of iterations\n",
    "    \n",
    "# OUTPUT\n",
    "# Sd_T: storage deficits corresponding with return periods T\n",
    "    \n",
    "\n",
    "def sr_return_periods_minmax_rzyear(T,Sd,it,year_start,year_end,date_start,date_end):\n",
    "\n",
    "    for j in range(len(T)):\n",
    "        Sd = Sd*-1\n",
    "        total_years = year_end - year_start\n",
    "        years = range(year_start,year_end+1,1)\n",
    "        \n",
    "        # calculate annual max Sd - without iterations for hydro years\n",
    "        Sd_max=[]\n",
    "        Sd_maxmin = []\n",
    "        for i in range(0,total_years,1):\n",
    "            sd_max_i = max(Sd.loc[str(years[i])+'-'+str(date_start):str(years[i+1])+'-'+str(date_end)]) #max value\n",
    "            Sd_max.append(sd_max_i) #append max deficit per year\n",
    "            \n",
    "            sd_max_ix = Sd.loc[str(years[i])+'-'+str(date_start):str(years[i+1])+'-'+str(date_end)].idxmax() #find index of max value\n",
    "            sd_hystart_maxvalue = Sd.loc[str(years[i])+'-'+str(date_start):sd_max_ix] #timeseries from start hydroyear to index of max value\n",
    "            min_value = min(sd_hystart_maxvalue) #find min value in timeseries before max value\n",
    "            Sd_maxmin.append(sd_max_i-min_value) #append max-min sd per year\n",
    "            \n",
    "        # define root zone year\n",
    "        sd_max_month = Sd.groupby(pd.Grouper(freq='M')).max() #calculate maximum sd per month\n",
    "        sd_max_month_sum =  sd_max_month.groupby([sd_max_month.index.month]).sum() #sum max sd per month for full timeseries per month\n",
    "        start_rz_year = sd_max_month_sum.idxmin() #define month where rz year starts\n",
    "        date_start_rz_year = str(start_rz_year)+'-1'        \n",
    "        if(start_rz_year==1):\n",
    "            start_rz_year=13\n",
    "        day_end_rz_year = calendar.monthrange(2010,start_rz_year-1)[1] #find last day of end month rz year\n",
    "        date_end_rz_year = str(start_rz_year-1)+'-'+str(day_end_rz_year)\n",
    "        \n",
    "        # calculate annual max Sd - without iterations for rootzone years -> CHECK THIS APPROACH\n",
    "        Sd_max_rz_year = []\n",
    "        Sd_maxmin_rz_year = []\n",
    "        for i in range(0,total_years,1):\n",
    "            sd_max_i = max(Sd.loc[str(years[i])+'-'+str(date_start_rz_year):str(years[i+1])+'-'+str(date_end_rz_year)])\n",
    "            Sd_max_rz_year.append(sd_max_i) #append max deficit per year\n",
    "            \n",
    "            sd_max_ix = Sd.loc[str(years[i])+'-'+str(date_start_rz_year):str(years[i+1])+'-'+str(date_end_rz_year)].idxmax() #find index of max value\n",
    "            sd_hystart_maxvalue = Sd.loc[str(years[i])+'-'+str(date_start_rz_year):sd_max_ix] #timeseries from start rzyear to index of max value\n",
    "            min_value = min(sd_hystart_maxvalue) #find min value in timeseries before max value\n",
    "            Sd_maxmin_rz_year.append(sd_max_i-min_value) #append max-min sd per year\n",
    "            \n",
    "        # gumbel function\n",
    "        def gumbel_r_mom(x):\n",
    "            scale = np.sqrt(6)/np.pi * np.std(x)\n",
    "            loc = np.mean(x) - np.euler_gamma*scale\n",
    "            return loc, scale    \n",
    "        \n",
    "        loc1, scale1 = gumbel_r_mom(Sd_maxmin_rz_year)\n",
    "                   \n",
    "        # find Sd value corresponding with return period\n",
    "        Sd_T = []\n",
    "        for i in np.arange(0,len(T),1):\n",
    "            p = 1-(1/T[i])\n",
    "            y = -np.log(-np.log(p))\n",
    "            x = scale1 * y + loc1\n",
    "            Sd_T.append(x)\n",
    "         \n",
    "        return(Sd_T)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40f35101-c65d-4d95-9ccd-4704f3465916",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% RUN SD CALCULATION\n",
    "\n",
    "a = np.genfromtxt('/home/vanoorschot/work/fransje/scripts/GLOBAL_SR/catch_id_selected_lowercase_wb.txt',dtype='str')\n",
    "names = a\n",
    "\n",
    "fol = '/home/vanoorschot/work/fransje/scripts/GLOBAL_SR'\n",
    "\n",
    "# q\n",
    "q = pd.read_csv(f'{fol}/p_q_ep_timeseries_selected_catchments/mean_q_p_ep.csv', index_col=0)\n",
    "        \n",
    "for i in range(len(names)):\n",
    "        # run initial Sd calculation\n",
    "        catchment_ts = pd.read_csv(f'{fol}/p_ep_timeseries_selected_catchments/daily/{names[i]}.csv',index_col=0)\n",
    "        catchment_ts.index = pd.to_datetime(catchment_ts.index)\n",
    "\n",
    "        df_monthly = pd.DataFrame(index=pd.date_range(catchment_ts.index[0],catchment_ts.index[-1],freq='M'), columns=['p','ep'])\n",
    "        df_monthly[['p','ep']] = catchment_ts[['p','ep']].groupby(pd.Grouper(freq=\"M\")).sum()\n",
    "\n",
    "        q_mean = q.loc[f'{names[i]}'].q # MAKE SURE CORRECT YEARS ARE USED FOR MEAN VALUES\n",
    "        \n",
    "        # calculate start hydroyear\n",
    "        df_monthly_mean = df_monthly.groupby([df_monthly.index.month]).mean()\n",
    "        wettest_month = (df_monthly_mean.p-df_monthly_mean.ep).idxmax()\n",
    "        hydro_year_start_month = wettest_month+1\n",
    "        if hydro_year_start_month==13:\n",
    "            hydro_year_start_month=1\n",
    "        \n",
    "        start_year = catchment_ts.index.year[0]\n",
    "        end_year = catchment_ts.index.year[-1]\n",
    "        start_date = datetime(start_year,hydro_year_start_month,1)\n",
    "        end_date = datetime(end_year,hydro_year_start_month,1)\n",
    "        end_date = end_date - timedelta(days=1)\n",
    "        \n",
    "        # GSWP data\n",
    "        sd_input = pd.DataFrame(index=catchment_ts.index, columns=['p','ep','date_start','date_end'])\n",
    "        sd_input[['p','ep']] = catchment_ts[['p','ep']]\n",
    "        sd_input[['date_start','date_end']] = start_date, end_date\n",
    "        Si_0 = 0\n",
    "        Si_max = 2.5\n",
    "        out = sd_initial(sd_input, Si_0, Si_max, q_mean)\n",
    "        out.to_csv(f'{fol}/sr_calculation/gswp_gleam/sd_catchments/'+str(names[i])+'.csv')\n",
    "    \n",
    "        # print(i)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eae57088-877b-4031-be95-e11e95cd27c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% RUN SR CALCULATION\n",
    "# SR\n",
    "def sr_calc(names,fol):\n",
    "    sr_df = pd.DataFrame(index=names, columns=['Sr_2','Sr_3','Sr_5','Sr_10','Sr_20','Sr_30','Sr_40','Sr_50','Sr_60'])\n",
    "    for k in range(len(names)):\n",
    "    # for k in range(1000):\n",
    "        if(path.exists(f'{fol}/sr_calculation/gswp_gleam/sd_catchments/'+str(names[k])+'.csv')==True):  \n",
    "            out = pd.read_csv(f'{fol}/sr_calculation/gswp_gleam/sd_catchments/'+str(names[k])+'.csv',index_col=0)\n",
    "            out.index = pd.to_datetime(out.index)\n",
    "            # run SR calculation based on intial Sd calculation (without iterations)\n",
    "            T = [2,3,5,10,20,30,40,50,60]\n",
    "            if out.empty:\n",
    "                continue\n",
    "            Sd = out.Sd\n",
    "            if(np.isnan(Sd[0])):\n",
    "                continue\n",
    "            it=0\n",
    "            year_start = out.index[0].year\n",
    "            year_end = out.index[-1].year\n",
    "            date_start = str(out.index[0].month)+'-'+str(out.index[0].day)\n",
    "            date_end = str(out.index[-1].month)+'-'+str(out.index[-1].day)\n",
    "            if(date_end=='2-29'):\n",
    "                date_end='2-28'\n",
    "            sr_T = sr_return_periods_minmax_rzyear(T,Sd,it,year_start,year_end,date_start,date_end)\n",
    "            sr_df.loc[names[k],:] = sr_T\n",
    "            # print(k)\n",
    "    sr_df.to_csv(f'{fol}/sr_calculation/gswp_gleam/sr_df.csv')\n",
    "    \n",
    "    return(sr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "995a0e79-2962-4803-9cc4-7c46f1818443",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.genfromtxt('/home/vanoorschot/work/fransje/scripts/GLOBAL_SR/catch_id_selected_lowercase_wb.txt',dtype='str')\n",
    "names = a\n",
    "fol = '/home/vanoorschot/work/fransje/scripts/GLOBAL_SR'\n",
    "\n",
    "sr = sr_calc(names,fol)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cb0d6f7-891e-4047-b396-bd5cbbfe332d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sr_2</th>\n",
       "      <th>Sr_3</th>\n",
       "      <th>Sr_5</th>\n",
       "      <th>Sr_10</th>\n",
       "      <th>Sr_20</th>\n",
       "      <th>Sr_30</th>\n",
       "      <th>Sr_40</th>\n",
       "      <th>Sr_50</th>\n",
       "      <th>Sr_60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>br_0000078</th>\n",
       "      <td>110.54926</td>\n",
       "      <td>122.900463</td>\n",
       "      <td>136.657039</td>\n",
       "      <td>153.94266</td>\n",
       "      <td>170.523442</td>\n",
       "      <td>180.061958</td>\n",
       "      <td>186.786905</td>\n",
       "      <td>191.985565</td>\n",
       "      <td>196.224214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>br_0003083</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr_0001029</th>\n",
       "      <td>164.265834</td>\n",
       "      <td>186.934675</td>\n",
       "      <td>212.182874</td>\n",
       "      <td>243.908125</td>\n",
       "      <td>274.339747</td>\n",
       "      <td>291.846308</td>\n",
       "      <td>304.188975</td>\n",
       "      <td>313.73036</td>\n",
       "      <td>321.509786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_0000013</th>\n",
       "      <td>57.644383</td>\n",
       "      <td>76.158138</td>\n",
       "      <td>96.778466</td>\n",
       "      <td>122.688634</td>\n",
       "      <td>147.542289</td>\n",
       "      <td>161.839984</td>\n",
       "      <td>171.9203</td>\n",
       "      <td>179.712796</td>\n",
       "      <td>186.066292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>za_0000059</th>\n",
       "      <td>315.733302</td>\n",
       "      <td>337.360425</td>\n",
       "      <td>361.448375</td>\n",
       "      <td>391.715732</td>\n",
       "      <td>420.748907</td>\n",
       "      <td>437.450977</td>\n",
       "      <td>449.226452</td>\n",
       "      <td>458.329374</td>\n",
       "      <td>465.751306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312061</th>\n",
       "      <td>133.803468</td>\n",
       "      <td>152.308611</td>\n",
       "      <td>172.919349</td>\n",
       "      <td>198.817466</td>\n",
       "      <td>223.659562</td>\n",
       "      <td>237.950606</td>\n",
       "      <td>248.026235</td>\n",
       "      <td>255.815106</td>\n",
       "      <td>262.165647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314207</th>\n",
       "      <td>212.486429</td>\n",
       "      <td>237.086591</td>\n",
       "      <td>264.485866</td>\n",
       "      <td>298.914018</td>\n",
       "      <td>331.938328</td>\n",
       "      <td>350.936398</td>\n",
       "      <td>364.330625</td>\n",
       "      <td>374.684909</td>\n",
       "      <td>383.12712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314213</th>\n",
       "      <td>373.733461</td>\n",
       "      <td>405.356027</td>\n",
       "      <td>440.576744</td>\n",
       "      <td>484.832814</td>\n",
       "      <td>527.284299</td>\n",
       "      <td>551.705591</td>\n",
       "      <td>568.923357</td>\n",
       "      <td>582.233392</td>\n",
       "      <td>593.085531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315450</th>\n",
       "      <td>212.716749</td>\n",
       "      <td>239.877664</td>\n",
       "      <td>270.129064</td>\n",
       "      <td>308.141012</td>\n",
       "      <td>344.602985</td>\n",
       "      <td>365.578658</td>\n",
       "      <td>380.367156</td>\n",
       "      <td>391.799269</td>\n",
       "      <td>401.120271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318076</th>\n",
       "      <td>116.911057</td>\n",
       "      <td>132.809779</td>\n",
       "      <td>150.517526</td>\n",
       "      <td>172.767932</td>\n",
       "      <td>194.111056</td>\n",
       "      <td>206.389229</td>\n",
       "      <td>215.04572</td>\n",
       "      <td>221.737541</td>\n",
       "      <td>227.193617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7782 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Sr_2        Sr_3        Sr_5       Sr_10       Sr_20  \\\n",
       "br_0000078   110.54926  122.900463  136.657039   153.94266  170.523442   \n",
       "br_0003083         0.0         0.0         0.0         0.0         0.0   \n",
       "fr_0001029  164.265834  186.934675  212.182874  243.908125  274.339747   \n",
       "id_0000013   57.644383   76.158138   96.778466  122.688634  147.542289   \n",
       "za_0000059  315.733302  337.360425  361.448375  391.715732  420.748907   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "312061      133.803468  152.308611  172.919349  198.817466  223.659562   \n",
       "314207      212.486429  237.086591  264.485866  298.914018  331.938328   \n",
       "314213      373.733461  405.356027  440.576744  484.832814  527.284299   \n",
       "315450      212.716749  239.877664  270.129064  308.141012  344.602985   \n",
       "318076      116.911057  132.809779  150.517526  172.767932  194.111056   \n",
       "\n",
       "                 Sr_30       Sr_40       Sr_50       Sr_60  \n",
       "br_0000078  180.061958  186.786905  191.985565  196.224214  \n",
       "br_0003083         0.0         0.0         0.0         0.0  \n",
       "fr_0001029  291.846308  304.188975   313.73036  321.509786  \n",
       "id_0000013  161.839984    171.9203  179.712796  186.066292  \n",
       "za_0000059  437.450977  449.226452  458.329374  465.751306  \n",
       "...                ...         ...         ...         ...  \n",
       "312061      237.950606  248.026235  255.815106  262.165647  \n",
       "314207      350.936398  364.330625  374.684909   383.12712  \n",
       "314213      551.705591  568.923357  582.233392  593.085531  \n",
       "315450      365.578658  380.367156  391.799269  401.120271  \n",
       "318076      206.389229   215.04572  221.737541  227.193617  \n",
       "\n",
       "[7782 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18610cb2-eb47-46e1-a581-4ae9cfcef125",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
